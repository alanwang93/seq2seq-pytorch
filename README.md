# Sequence to sequence implementation with PyTorch

Seq2seq model with global attention, implemented with PyTorch.



## Reference:
- OpenNMT-py: https://github.com/OpenNMT/OpenNMT-py
- Pytorch NMT tutorial: http://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html (Note that the tutorial has some faults)
- torchtext: https://github.com/pytorch/text
- Effective Approaches to Attention-based Neural Machine Translation
- Neural Text Generation: A Practical Guide
